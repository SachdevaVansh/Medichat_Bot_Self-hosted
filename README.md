# MediChat Bot (Self-Hosted) ğŸ¥ğŸ¤–

A self-hosted, enterprise-ready medical chatbot â€” now fully containerizable and deployable for hospital/clinical use.

ğŸš€ Whatâ€™s New / Why This Matters

Self-hosted LLM: Running gptâ€‘ossâ€‘20B on your own GPU server â€” no external API dependency, ensuring full data ownership and privacy.

Secure cloud document storage: Integrated AWS S3 (or any S3-compatible storage) for encrypted medical document uploads, enabling HIPAA-style compliance and scalable storage.

Vector store on cloud with real-time indexing: Now uses ChromaDB (cloud vector store) â€” every time a document is uploaded, embeddings are generated and stored instantly, enabling fast, context-aware retrieval.

Enterprise-ready RAG pipeline: Combines self-hosted LLM + multilingual embedding model + cloud vector DB + secure storage â€” making the system ready for real-world deployment in hospitals, clinics or healthtech products.

ğŸ’¡ What Does MediChat Do?

- Allows hospitals / healthcare providers to upload PDF medical reports (labs, prescriptions, discharge summaries, medical history, etc.) into a secure storage backend.

- Automatically processes and indexes documents via embedding + vector store, enabling semantic search.

- Lets users â€” patients or doctors â€” ask free-form questions in natural language and receive accurate, context-grounded answers generated by the self-hosted LLM.

- Retains conversation history for follow-up queries and auditability.

- Fully under your control â€” no external service, no third-party data leaks, suitable for sensitive medical data.

ğŸ§° Tech Stack

- LLM / Embeddings: gpt-oss-20B (self-hosted), multilingual embedding model (hosted separately)

- Vector Store & Retrieval: ChromaDB (cloud) for storing and retrieving embeddings in real-time

- Document Storage: AWS S3 (or S3-compatible storage) for secure PDF storage

- RAG Pipeline / Orchestration: LangChain + custom vector-store utils + PDF utilities

- Frontend / UI: Streamlit for web interface â€” upload, chat, view history

- Backend & Deployment: Python, modular codebase â€” easily containerized (Docker) or deployed on on-prem servers / cloud VMs

- Data Privacy & Compliance Focused: Self-hosting + secure cloud storage + no third-party API calls

âœ… Features â€” Production-Ready Edition

- Self-hosted, open-source LLM stack â€” full data ownership & no vendor lock-in

- Secure storage of sensitive medical documents with S3 integration

- Instant embedding & indexing into a scalable vector store (ChromaDB)

- Real-time conversational Q&A grounded in user-uploaded documents

- Retained chat history for context and follow-up queries

- Modular architecture â€” easy to deploy in hospital/enterprise environments

ğŸ“¦ How to Run / Deploy

- Clone the repository

- Set up a GPU server (for gpt-oss-20B inference) and a separate machine for the embedding model (or combine based on resource availability)

- Configure environment variables for S3 credentials (or S3-compatible storage) and vector store endpoint

- Install dependencies via requirements.txt

- Run the Streamlit UI (or wrap in a web-service / container)

âš ï¸ Disclaimer

This tool is built for informational and demonstrative purposes. It is not a substitute for professional medical advice, diagnosis, or treatment. Always seek consultation from a qualified healthcare professional for medical decisions.
